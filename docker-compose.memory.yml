# Memory components add-on for conversation persistence and speaker identification
services:
  orchestrator:
    build: ./orchestrator
    environment:
      - MEMORY_ENABLED=true
      - CHROMADB_URL=http://chromadb:8000
      - REDIS_URL=redis://redis:6379
      - WHISPER_URL=${WHISPER_URL:-http://whisper-live:9090}
      - OLLAMA_URL=${OLLAMA_URL:-http://host.docker.internal:11434}
      - TTS_URL=${TTS_URL:-http://kokoro:8880}
      - LLM_MODEL=${LLM_MODEL:-gemma3n:latest}
      - TTS_VOICE=${TTS_VOICE:-af_bella}
    depends_on:
      chromadb:
        condition: service_healthy
      redis:
        condition: service_started
      whisper-live:
        condition: service_started
      kokoro:
        condition: service_started


  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru
    restart: unless-stopped

  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8002:8000"
    volumes:
      - ./data/chromadb:/data
    environment:
      - ANONYMIZED_TELEMETRY=FALSE
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v2/heartbeat"]
      interval: 10s
      timeout: 10s
      retries: 15
    restart: unless-stopped

  whisper-live:
    build:
      context: https://github.com/collabora/WhisperLive.git
      dockerfile: docker/Dockerfile.gpu
    ports:
      - "9090:9090"
    volumes:
      - ./data/models/whisper:/models
    environment:
      - MODEL_SIZE=${STT_MODEL:-tiny}
      - VAD_ENABLED=true
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  kokoro:
    image: ghcr.io/remsky/kokoro-fastapi-gpu:v0.2.1
    ports:
      - "8880:8880"
    environment:
      - DEFAULT_VOICE=${TTS_VOICE:-af_bella}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  voice-ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    ports:
      - "3001:3001"
    environment:
      - ORCHESTRATOR_URL=${ORCHESTRATOR_URL:-http://orchestrator:8000}
      - NEXT_PUBLIC_WHISPER_WS_URL=${WHISPER_WS_URL:-ws://localhost:9090}
    depends_on:
      - orchestrator
    restart: unless-stopped

volumes:
  diglett-data: