# docker-compose.yml - Refactored Central Orchestrator Architecture
services:
  # Central Stream Orchestrator - The heart of the system
  orchestrator:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      # Service URLs - Orchestrator coordinates all connections
      - WHISPER_URL=${WHISPER_URL:-http://whisper-live:9090}
      - OLLAMA_URL=${OLLAMA_URL:-http://host.docker.internal:11434}
      - TTS_URL=${TTS_URL:-http://kokoro:8880}
      - MEMORY_ENABLED=${MEMORY_ENABLED:-false}
      - AMEM_URL=${AMEM_URL:-http://a-mem:8001}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
      
      # Model Configuration
      - STT_MODEL=${STT_MODEL:-tiny}
      - LLM_MODEL=${LLM_MODEL:-gemma3n:latest}
      - TTS_VOICE=${TTS_VOICE:-af_bella}
      
      # Processing Parameters
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-512}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.7}
      - TTS_SPEED=${TTS_SPEED:-1.0}
      - TTS_VOLUME=${TTS_VOLUME:-1.0}
      
      # Audio Processing
      - CHUNK_SIZE=${CHUNK_SIZE:-256}
      - MIN_WORD_COUNT=${MIN_WORD_COUNT:-3}
      
      # WhisperLive Settings
      - NO_SPEECH_THRESHOLD=${NO_SPEECH_THRESHOLD:-0.45}
      - VAD_ENABLED=${VAD_ENABLED:-true}
      
      # Timeouts
      - OLLAMA_TIMEOUT=${OLLAMA_TIMEOUT:-30.0}
      - TTS_TIMEOUT=${TTS_TIMEOUT:-10.0}
      - AMEM_TIMEOUT=${AMEM_TIMEOUT:-5.0}
      
    depends_on:
      - whisper-live
      - kokoro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - voice-net

  # WhisperLive - Speech-to-Text Service (Backend only, no direct frontend connection)
  whisper-live:
    build:
      context: https://github.com/collabora/WhisperLive.git
      dockerfile: docker/Dockerfile.gpu
    ports:
      - "9090:9090"  # Only for orchestrator connection
    volumes:
      - ./data/models/whisper:/models
    environment:
      - MODEL_SIZE=${STT_MODEL:-tiny}
      - VAD_ENABLED=${VAD_ENABLED:-true}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      # WhisperLive specific settings for optimal orchestrator integration
      - MAX_CLIENTS=10  # Increased for orchestrator pooling
      - MAX_CONNECTION_TIME=7200  # 2 hours
      - SEND_LAST_N_SEGMENTS=5  # Optimized for real-time
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - voice-net

  # Kokoro TTS - Text-to-Speech Service (Backend only)
  kokoro:
    image: ghcr.io/remsky/kokoro-fastapi-gpu:v0.2.1
    ports:
      - "8880:8880"  # Only for orchestrator connection
    environment:
      - DEFAULT_VOICE=${TTS_VOICE:-af_bella}
      # Optimized for sentence-level streaming
      - MAX_CONCURRENT_REQUESTS=20
      - ENABLE_STREAMING=true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8880/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - voice-net

  # Frontend UI - Now connects only to orchestrator
  voice-ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    ports:
      - "3001:3001"
    environment:
      # Simplified environment - only needs orchestrator
      - NEXT_PUBLIC_ORCHESTRATOR_WS_URL=${NEXT_PUBLIC_ORCHESTRATOR_WS_URL:-ws://localhost:8000}
      - ORCHESTRATOR_HTTP_URL=${ORCHESTRATOR_HTTP_URL:-http://orchestrator:8000}
      # No direct WhisperLive connection needed
      - NODE_ENV=${NODE_ENV:-production}
    depends_on:
      - orchestrator
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - voice-net

  # Optional: Memory Service (A-MEM) - Only if memory is enabled
  a-mem:
    profiles: ["with-memory"]  # Only start if memory profile is activated
    image: your-amem-image:latest  # Replace with your A-MEM image
    ports:
      - "8001:8001"
    environment:
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
      - VECTOR_DB_URL=${VECTOR_DB_URL:-http://chromadb:8000}
    depends_on:
      - redis
      - chromadb
    restart: unless-stopped
    networks:
      - voice-net

  # Optional: Redis for session storage and caching
  redis:
    profiles: ["with-memory"]
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    command: redis-server --appendonly yes
    restart: unless-stopped
    networks:
      - voice-net

  # Optional: ChromaDB for vector storage
  chromadb:
    profiles: ["with-memory"]
    image: chromadb/chroma:latest
    ports:
      - "8100:8000"
    volumes:
      - ./data/chromadb:/chroma/chroma
    environment:
      - CHROMA_SERVER_AUTH_CREDENTIALS_FILE=/chroma/chroma/auth.txt
      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=chromadb.auth.basic_authn.BasicAuthCredentialsProvider
    restart: unless-stopped
    networks:
      - voice-net

# Network configuration
networks:
  voice-net:
    name: voice-orchestrator-net
    driver: bridge

# Volumes for persistent data
volumes:
  whisper-models:
    driver: local
  redis-data:
    driver: local
  chroma-data:
    driver: local